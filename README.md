Recent advances in machine learning, such as deep learning, have been shown to drastically improve the development of molecular potential energy models with a significantly smaller computational cost. One of the most prominent contributions in this area is the ANI-1 model, which demonstrated that neural network potentials (NNPs) trained on density functional theory (DFT) data can generalize well to diverse organic molecules (Smith et al., 2017). ANI-1 achieved this by combining a molecular representation based on atomic environment vectors (AEVs) with a high-capacity feedforward neural network architecture, allowing for accurate energy predictions for molecules larger than those seen during training.
While ANI-1 shows an advanced ability for generalization as mentioned in the paper mentioned above, its training strategy did not include key regularization techniques commonly used in modern deep learning. Specifically, the model omitted dropout and L2 regularization, two widely adopted methods for controlling overfitting and improving model performance. Instead, ANI-1 relied on architectural tuning, learning rate decay, and max-norm constraints to regularize training. However, with neural network potentials often trained on limited and highly correlated data, especially in smaller chemical domains, not including dropout and L2 leaves open questions about their potential to further stabilize learning and improve generalization. These regularization techniques can affect not only predictive performance but also convergence behavior and transferability. While these methods have been studied extensively in general deep learning contexts, their combined effects have not been systematically studied in the setting of molecular energy prediction, especially within architectures like ANI. In this project, we aim to systematically investigate the individual and combined effects of dropout and L2 regularization on the training and performance of ANI-style neural network potentials.
